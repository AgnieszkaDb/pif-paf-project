{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(0)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "\n",
    "        out = self.fc(out)\n",
    "        # out = self.sigmoid(out)\n",
    "        # predicted_class = torch.where(out > 0.5, torch.tensor(0.0), torch.tensor(1.0))\n",
    "        return out\n",
    "        # return predicted_class\n",
    "\n",
    "input_size = 2\n",
    "hidden_size = 32\n",
    "num_layers = 10\n",
    "output_size = 1\n",
    "\n",
    "model = LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, output_size=output_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_dir = '../data/emg_rms/'\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, file_list):\n",
    "        self.file_list = file_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = os.path.join(data_dir, self.file_list[idx])\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        features = df[['V1', 'V2']].values\n",
    "        label = df[df.columns[-1]].loc[0]\n",
    "\n",
    "        return torch.FloatTensor(features), label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = os.listdir(data_dir)\n",
    "\n",
    "train_files, val_files = train_test_split(file_list, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = CustomDataset(train_files)\n",
    "val_dataset = CustomDataset(val_files)\n",
    "\n",
    "batch_size = 1\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs[0], labels)\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs[0], labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "        average_val_loss = val_loss / len(val_loader)\n",
    "        accuracy = total_correct / total_samples\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Validation Loss: {average_val_loss:.4f}, Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data_dir = '../data/emg_rms/'\n",
    "transformed_dfs = []\n",
    "\n",
    "def calculate_wave_shape(x):\n",
    "    x = np.array(x, dtype=np.float32)\n",
    "    differences = np.abs(x[1:] - x[:-1])\n",
    "\n",
    "    wave_shape = differences.sum()\n",
    "\n",
    "    return wave_shape\n",
    "\n",
    "def calculate_mean_signal_energy(x):\n",
    "    x = np.array(x)\n",
    "    sum_squared_values = np.sum(x**2)\n",
    "\n",
    "    mean_signal_energy = sum_squared_values / len(x)\n",
    "\n",
    "    return mean_signal_energy\n",
    "\n",
    "\n",
    "for filename in os.listdir(data_dir):\n",
    "    file_path = os.path.join(data_dir, filename)\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    mae_v1 = df['V1'].abs().mean()\n",
    "    ws_v1 = calculate_wave_shape(df['V1'])\n",
    "    sen_v1 = calculate_mean_signal_energy(df['V1'])\n",
    "\n",
    "    mae_v2 = df['V2'].abs().mean()\n",
    "    ws_v2 = calculate_wave_shape(df['V2'])\n",
    "    sen_v2 = calculate_mean_signal_energy(df['V2'])\n",
    "\n",
    "    label = df[df.columns[-1]].iloc[0]\n",
    "\n",
    "    features = {\n",
    "        'MAE_V1': mae_v1,\n",
    "        'WS_V1': ws_v1,\n",
    "        'SEN_V1': sen_v1,\n",
    "        'MAE_V2': mae_v2,\n",
    "        'WS_V2': ws_v2,\n",
    "        'SEN_V2': sen_v2,\n",
    "        'Label': label\n",
    "    }\n",
    "\n",
    "    transformed_df = pd.DataFrame([features])\n",
    "\n",
    "    transformed_dfs.append(transformed_df)\n",
    "\n",
    "final_df = pd.concat(transformed_dfs, ignore_index=True)\n",
    "\n",
    "# print(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 1/90, Validation Loss: 0.6668, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 2/90, Validation Loss: 0.6475, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 3/90, Validation Loss: 0.6282, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 4/90, Validation Loss: 0.6087, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 5/90, Validation Loss: 0.5889, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 6/90, Validation Loss: 0.5690, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 7/90, Validation Loss: 0.5490, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 8/90, Validation Loss: 0.5295, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 9/90, Validation Loss: 0.5113, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 10/90, Validation Loss: 0.4950, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 11/90, Validation Loss: 0.4818, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 12/90, Validation Loss: 0.4722, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 13/90, Validation Loss: 0.4663, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 14/90, Validation Loss: 0.4633, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 15/90, Validation Loss: 0.4621, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 16/90, Validation Loss: 0.4617, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 17/90, Validation Loss: 0.4612, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 18/90, Validation Loss: 0.4603, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 19/90, Validation Loss: 0.4590, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 20/90, Validation Loss: 0.4573, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 21/90, Validation Loss: 0.4553, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 22/90, Validation Loss: 0.4532, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 23/90, Validation Loss: 0.4509, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 24/90, Validation Loss: 0.4487, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 25/90, Validation Loss: 0.4464, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 26/90, Validation Loss: 0.4442, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 27/90, Validation Loss: 0.4421, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 28/90, Validation Loss: 0.4400, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 29/90, Validation Loss: 0.4380, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 30/90, Validation Loss: 0.4362, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 31/90, Validation Loss: 0.4344, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 32/90, Validation Loss: 0.4328, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 33/90, Validation Loss: 0.4312, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 34/90, Validation Loss: 0.4297, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 35/90, Validation Loss: 0.4282, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 36/90, Validation Loss: 0.4268, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 37/90, Validation Loss: 0.4253, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 38/90, Validation Loss: 0.4239, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 39/90, Validation Loss: 0.4225, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 40/90, Validation Loss: 0.4210, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 41/90, Validation Loss: 0.4195, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 42/90, Validation Loss: 0.4181, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 43/90, Validation Loss: 0.4166, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 44/90, Validation Loss: 0.4152, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 45/90, Validation Loss: 0.4139, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 46/90, Validation Loss: 0.4128, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 47/90, Validation Loss: 0.4119, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 48/90, Validation Loss: 0.4113, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 49/90, Validation Loss: 0.4108, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 50/90, Validation Loss: 0.4104, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 51/90, Validation Loss: 0.4099, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 52/90, Validation Loss: 0.4091, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 53/90, Validation Loss: 0.4082, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 54/90, Validation Loss: 0.4073, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 55/90, Validation Loss: 0.4066, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 56/90, Validation Loss: 0.4062, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 57/90, Validation Loss: 0.4062, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 58/90, Validation Loss: 0.4063, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 59/90, Validation Loss: 0.4063, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 60/90, Validation Loss: 0.4061, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 61/90, Validation Loss: 0.4059, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 62/90, Validation Loss: 0.4059, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 63/90, Validation Loss: 0.4061, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 64/90, Validation Loss: 0.4065, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 65/90, Validation Loss: 0.4068, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 66/90, Validation Loss: 0.4069, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 67/90, Validation Loss: 0.4071, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 68/90, Validation Loss: 0.4075, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 69/90, Validation Loss: 0.4079, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 70/90, Validation Loss: 0.4083, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 71/90, Validation Loss: 0.4087, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 72/90, Validation Loss: 0.4091, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 73/90, Validation Loss: 0.4096, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 74/90, Validation Loss: 0.4101, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 75/90, Validation Loss: 0.4106, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 76/90, Validation Loss: 0.4110, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 77/90, Validation Loss: 0.4115, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 78/90, Validation Loss: 0.4121, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 79/90, Validation Loss: 0.4126, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 80/90, Validation Loss: 0.4132, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 81/90, Validation Loss: 0.4137, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 82/90, Validation Loss: 0.4143, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 83/90, Validation Loss: 0.4149, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 84/90, Validation Loss: 0.4154, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 85/90, Validation Loss: 0.4160, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 86/90, Validation Loss: 0.4166, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 87/90, Validation Loss: 0.4173, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 88/90, Validation Loss: 0.4179, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 89/90, Validation Loss: 0.4185, Accuracy: 0.8667\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.])\n",
      "Epoch 90/90, Validation Loss: 0.4192, Accuracy: 0.8667\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features_columns = ['MAE_V1', 'WS_V1', 'SEN_V1', 'MAE_V2', 'WS_V2', 'SEN_V2']\n",
    "label_column = 'Label'\n",
    "\n",
    "features = final_df[features_columns].values\n",
    "labels = final_df[label_column].values\n",
    "\n",
    "features_tensor = torch.FloatTensor(features)\n",
    "labels_tensor = torch.FloatTensor(labels)\n",
    "\n",
    "dataset = TensorDataset(features_tensor, labels_tensor)\n",
    "\n",
    "train_size = int(0.75 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = train_test_split(dataset,test_size=0.3, train_size=0.7)\n",
    "# from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "# sampler = WeightedRandomSampler([0.5, 0.5], 2, replacement=True)\n",
    "\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "input_size = len(features_columns)\n",
    "hidden_size = 32\n",
    "num_layers = 2\n",
    "output_size = 1\n",
    "model = LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, output_size=output_size)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 90\n",
    "threshold = 0.9\n",
    "loss_val = []\n",
    "acc_val = []\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs).view(-1, 1)\n",
    "\n",
    "        labels = labels.view(-1, 1)\n",
    "\n",
    "        predicted_probs = torch.sigmoid(outputs)\n",
    "        predicted_labels = (predicted_probs > threshold).float()\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs).view(-1, 1)\n",
    "            print(labels)\n",
    "\n",
    "            labels = labels.view(-1, 1)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            predicted_probs = torch.sigmoid(outputs)\n",
    "            predicted_labels = (predicted_probs > threshold).float()\n",
    "\n",
    "            total_correct += (predicted_labels == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "        average_val_loss = val_loss / len(val_loader)\n",
    "        accuracy = total_correct / total_samples\n",
    "\n",
    "        loss_val.append(average_val_loss)\n",
    "        acc_val.append(accuracy)\n",
    "\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Validation Loss: {average_val_loss:.4f}, Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = range(1, len(loss_val) + 1)\n",
    "plt.plot(epochs, acc_val, label='Accuracy')\n",
    "plt.plot(epochs, loss_val, label='Loss')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
