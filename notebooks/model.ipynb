{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        out = self.sigmoid(out)\n",
    "        predicted_class = torch.where(out > 0.5, torch.tensor(0.0), torch.tensor(1.0))\n",
    "\n",
    "        return predicted_class\n",
    "\n",
    "input_size = 2\n",
    "hidden_size = 32\n",
    "num_layers = 10\n",
    "output_size = 1\n",
    "\n",
    "model = LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, output_size=output_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_dir = '../data/emg_rms/'\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, file_list):\n",
    "        self.file_list = file_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = os.path.join(data_dir, self.file_list[idx])\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        features = df[['V1', 'V2']].values\n",
    "        label = df[df.columns[-1]].loc[0]\n",
    "\n",
    "        return torch.FloatTensor(features), label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = os.listdir(data_dir)\n",
    "\n",
    "train_files, val_files = train_test_split(file_list, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = CustomDataset(train_files)\n",
    "val_dataset = CustomDataset(val_files)\n",
    "\n",
    "batch_size = 1\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs[0], labels)\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs[0], labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "        average_val_loss = val_loss / len(val_loader)\n",
    "        accuracy = total_correct / total_samples\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Validation Loss: {average_val_loss:.4f}, Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        MAE_V1   WS_V1         SEN_V1      MAE_V2   WS_V2         SEN_V2  \\\n",
      "0   348.522222  2644.0  125437.677778  379.955556   967.0  145912.822222   \n",
      "1   354.861386  2650.0  129046.584158  385.287129  1103.0  150835.900990   \n",
      "2   439.800000  1670.0  208374.200000  339.250000   702.0  115821.116667   \n",
      "3   355.010000  2559.0  129251.330000  372.510000  1051.0  141210.510000   \n",
      "4   361.648649  1531.0  136412.567568  368.837838   317.0  138069.594595   \n",
      "5   335.500000  2376.0  120302.933333  363.650000   643.0  132562.516667   \n",
      "6   340.886364  2301.0  126652.204545  360.318182   446.0  130171.045455   \n",
      "7   437.260000  1335.0  204210.060000  335.060000   951.0  113620.260000   \n",
      "8   342.957143  2582.0  123893.157143  374.057143   733.0  140688.142857   \n",
      "9   358.355263  2849.0  134479.697368  377.736842   801.0  144415.605263   \n",
      "10  343.000000  2648.0  122369.945946  383.162162   899.0  147863.972973   \n",
      "11  399.200000  2667.0  179185.828571  364.085714  1918.0  144233.971429   \n",
      "12  372.480000  1261.0  145202.400000  377.520000   703.0  143590.560000   \n",
      "13  355.300000  2587.0  128794.360000  374.070000   945.0  142297.110000   \n",
      "14  345.160494  3749.0  129148.172840  352.629630  3131.0  132199.493827   \n",
      "15  375.769231  3743.0  160911.884615  386.307692  1080.0  152936.384615   \n",
      "16  381.627907  3059.0  162311.627907  339.604651  2354.0  126024.581395   \n",
      "17  365.853333  2933.0  142433.693333  393.520000  1066.0  157950.506667   \n",
      "18  343.762500  2716.0  122699.587500  376.862500   950.0  144557.912500   \n",
      "19  356.195652  3039.0  143521.760870  364.347826  2414.0  144235.173913   \n",
      "20  349.136364  2658.0  130719.712121  352.515152  1239.0  124998.151515   \n",
      "21  371.263158  3968.0  148018.368421  405.736842  1376.0  171346.236842   \n",
      "22  336.650000  3338.0  134811.100000  328.650000  2097.0  121780.300000   \n",
      "23  365.076923  2533.0  140113.938462  390.738462   810.0  154771.815385   \n",
      "24  378.142857  3669.0  154818.542857  363.257143   930.0  132367.885714   \n",
      "25  346.064516  2835.0  129536.870968  374.129032   708.0  140482.419355   \n",
      "26  370.774194  2468.0  139844.903226  373.881720  1192.0  142709.903226   \n",
      "27  406.121951  1985.0  178522.170732  336.048780  1008.0  114711.219512   \n",
      "28  361.623116  6334.0  135213.984925  363.226131  2150.0  132829.959799   \n",
      "29  370.852632  4352.0  147177.021053  375.294737  1633.0  141742.852632   \n",
      "30  360.283186  3198.0  132855.575221  393.168142  1132.0  158291.628319   \n",
      "31  396.108696  2307.0  167009.152174  376.978261   745.0  143706.326087   \n",
      "32  443.775000  1270.0  211679.325000  400.900000   537.0  162401.050000   \n",
      "33  350.355556  2863.0  136676.222222  400.577778   917.0  164639.288889   \n",
      "34  353.011628  2464.0  126541.965116  380.523256   836.0  146481.988372   \n",
      "35  345.840000  2188.0  127171.600000  392.140000   850.0  157859.460000   \n",
      "36  413.095238  1636.0  181193.714286  346.214286   886.0  121130.404762   \n",
      "37  370.907895  3173.0  145735.907895  365.223684  1028.0  134657.223684   \n",
      "38  364.436170  2476.0  135594.393617  388.425532  1071.0  153145.787234   \n",
      "39  369.422222  3124.0  151806.222222  329.088889  2103.0  118570.200000   \n",
      "40  360.125000  2816.0  143252.625000  339.053571  1879.0  122397.089286   \n",
      "41  362.915493  1279.0  134253.140845  384.211268   934.0  148935.478873   \n",
      "42  386.013889  1258.0  153625.125000  370.555556   822.0  138053.388889   \n",
      "43  353.064103  3387.0  133637.910256  378.628205  1180.0  146799.653846   \n",
      "44  389.444444  2866.0  169153.666667  315.444444  1711.0  107992.833333   \n",
      "45  335.983333  2539.0  118092.550000  392.983333   907.0  158048.083333   \n",
      "46  339.326531  2966.0  128803.653061  363.979592  1889.0  143042.020408   \n",
      "47  356.757143  2873.0  132669.014286  389.742857   966.0  155568.742857   \n",
      "48  363.674419  2831.0  150684.697674  347.255814  2022.0  133302.465116   \n",
      "\n",
      "    Label  \n",
      "0     1.0  \n",
      "1     0.0  \n",
      "2     0.0  \n",
      "3     0.0  \n",
      "4     0.0  \n",
      "5     0.0  \n",
      "6     1.0  \n",
      "7     0.0  \n",
      "8     0.0  \n",
      "9     0.0  \n",
      "10    0.0  \n",
      "11    1.0  \n",
      "12    0.0  \n",
      "13    0.0  \n",
      "14    0.0  \n",
      "15    0.0  \n",
      "16    0.0  \n",
      "17    0.0  \n",
      "18    0.0  \n",
      "19    0.0  \n",
      "20    0.0  \n",
      "21    1.0  \n",
      "22    0.0  \n",
      "23    0.0  \n",
      "24    0.0  \n",
      "25    0.0  \n",
      "26    0.0  \n",
      "27    0.0  \n",
      "28    0.0  \n",
      "29    0.0  \n",
      "30    0.0  \n",
      "31    0.0  \n",
      "32    0.0  \n",
      "33    0.0  \n",
      "34    0.0  \n",
      "35    0.0  \n",
      "36    0.0  \n",
      "37    0.0  \n",
      "38    1.0  \n",
      "39    0.0  \n",
      "40    0.0  \n",
      "41    0.0  \n",
      "42    0.0  \n",
      "43    1.0  \n",
      "44    0.0  \n",
      "45    1.0  \n",
      "46    1.0  \n",
      "47    0.0  \n",
      "48    0.0  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data_dir = '../data/emg_rms/'\n",
    "transformed_dfs = []\n",
    "\n",
    "def calculate_wave_shape(x):\n",
    "    x = np.array(x, dtype=np.float32)\n",
    "    differences = np.abs(x[1:] - x[:-1])\n",
    "\n",
    "    wave_shape = differences.sum()\n",
    "\n",
    "    return wave_shape\n",
    "\n",
    "def calculate_mean_signal_energy(x):\n",
    "    # Convert the input to numpy array\n",
    "    x = np.array(x)\n",
    "\n",
    "    # Calculate the sum of squared values\n",
    "    sum_squared_values = np.sum(x**2)\n",
    "\n",
    "    # Calculate the Mean Signal Energy\n",
    "    mean_signal_energy = sum_squared_values / len(x)\n",
    "\n",
    "    return mean_signal_energy\n",
    "\n",
    "# Iterate through each file in the dataset directory\n",
    "for filename in os.listdir(data_dir):\n",
    "    file_path = os.path.join(data_dir, filename)\n",
    "\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Calculate MAE and MAV for each channel\n",
    "    mae_v1 = df['V1'].abs().mean()\n",
    "    ws_v1 = calculate_wave_shape(df['V1'])\n",
    "    sen_v1 = calculate_mean_signal_energy(df['V1'])\n",
    "\n",
    "    mae_v2 = df['V2'].abs().mean()\n",
    "    ws_v2 = calculate_wave_shape(df['V2'])\n",
    "    sen_v2 = calculate_mean_signal_energy(df['V2'])\n",
    "    # Get the label (assuming it's in the first row)\n",
    "    label = df[df.columns[-1]].iloc[0]\n",
    "\n",
    "    # Create a new DataFrame with the calculated features and label\n",
    "    features = {\n",
    "        'MAE_V1': mae_v1,\n",
    "        'WS_V1': ws_v1,\n",
    "        'SEN_V1': sen_v1,\n",
    "        'MAE_V2': mae_v2,\n",
    "        'WS_V2': ws_v2,\n",
    "        'SEN_V2': sen_v2,\n",
    "        'Label': label\n",
    "    }\n",
    "\n",
    "    transformed_df = pd.DataFrame([features])\n",
    "\n",
    "    # Append the DataFrame to the list\n",
    "    transformed_dfs.append(transformed_df)\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "final_df = pd.concat(transformed_dfs, ignore_index=True)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
